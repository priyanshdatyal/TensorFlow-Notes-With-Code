{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic_16_NeuralNetwork_StartingWithRegression2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM9s+iQAKlXFKX4KKYOYus1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyanshdatyal/TensorFlow-Notes-With-Code/blob/main/Topic_16_NeuralNetwork_StartingWithRegression2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Making"
      ],
      "metadata": {
        "id": "Zums6p7CZH6t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Creating a model - define input and output and all the hidden layers of the mdoel\n",
        "2. Define functions that tell how much is werror and how to improve the pattern of learning and evaluation matrix\n",
        "3. Fitting a model -letting thwe model find relations between X and y (features)"
      ],
      "metadata": {
        "id": "ChV2NHnQZiZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf \n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "nmtJEDojaKo6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([-7.0,-4.0,-1.0,2.0,5.0,8.0,11.0])\n",
        "\n",
        "y = np.array([3,6,9,12,15,18,21])\n",
        "\n",
        "plt.scatter(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "dswU9iH2bODd",
        "outputId": "f5b609b8-dfd3-4921-a9fb-167cce2cc583"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f15f2e2d790>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting seed\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae, # mae is short for mean absolute error\n",
        "              optimizer=tf.keras.optimizers.SGD(), # SGD is short for stochastic gradient descent\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Fit the model\n",
        "# model.fit(X, y, epochs=5) # this will break with TensorFlow 2.7.0+\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgp5XY3cZ2Ia",
        "outputId": "5cf2afe1-b6c3-423f-84a9-631b9a79bc1a"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 0s 492ms/step - loss: 10.8599 - mae: 10.8599\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 10.8099 - mae: 10.8099\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.7599 - mae: 10.7599\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.7099 - mae: 10.7099\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.6599 - mae: 10.6599\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f15ec202310>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X,y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44_xSldtfOdd",
        "outputId": "3636a9ce-18ec-446a-cb59-ed8333252c6d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-7., -4., -1.,  2.,  5.,  8., 11.]),\n",
              " array([ 3,  6,  9, 12, 15, 18, 21]))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([23.0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBlp9-TVfbjV",
        "outputId": "e185fdc7-cc9a-40c9-d3f2-edb98138639e"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[15.461375]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrong predicted valued but its is justieid as our mar show that value has a error of rround 13 points"
      ],
      "metadata": {
        "id": "HG4Mliekfjo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Improve this model as it is uselss\n",
        "\n",
        "1. Add more dense layers and add ativation or change activation\n",
        "2. change the optimization function or change the learning rate\n",
        "3. when we are fitting the mdole we can run the model for longer/ let the model use data more time => increase epochs"
      ],
      "metadata": {
        "id": "g-cWRCP9f5Ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tf.random.set_seed(45)\n",
        "\n",
        "# Create a model using the Sequential API\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile model (same as above)\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer=tf.keras.optimizers.Adam(lr=0.00375),\n",
        "              metrics=[\"mae\"])\n",
        "\n",
        "# Fit model (this time we'll train for longer)\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=230)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uw6Fbt5f9AE",
        "outputId": "bd3acc48-5bba-415b-bed2-22899313926f"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 520ms/step - loss: 12.0144 - mae: 12.0144\n",
            "Epoch 2/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.0000 - mae: 12.0000\n",
            "Epoch 3/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.9858 - mae: 11.9858\n",
            "Epoch 4/230\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.9719 - mae: 11.9719\n",
            "Epoch 5/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.9580 - mae: 11.9580\n",
            "Epoch 6/230\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.9440 - mae: 11.9440\n",
            "Epoch 7/230\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 11.9300 - mae: 11.9300\n",
            "Epoch 8/230\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.9158 - mae: 11.9158\n",
            "Epoch 9/230\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.9015 - mae: 11.9015\n",
            "Epoch 10/230\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.8870 - mae: 11.8870\n",
            "Epoch 11/230\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.8723 - mae: 11.8723\n",
            "Epoch 12/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.8574 - mae: 11.8574\n",
            "Epoch 13/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.8422 - mae: 11.8422\n",
            "Epoch 14/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.8267 - mae: 11.8267\n",
            "Epoch 15/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.8108 - mae: 11.8108\n",
            "Epoch 16/230\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.7946 - mae: 11.7946\n",
            "Epoch 17/230\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.7780 - mae: 11.7780\n",
            "Epoch 18/230\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 11.7610 - mae: 11.7610\n",
            "Epoch 19/230\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.7435 - mae: 11.7435\n",
            "Epoch 20/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.7256 - mae: 11.7256\n",
            "Epoch 21/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.7072 - mae: 11.7072\n",
            "Epoch 22/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.6884 - mae: 11.6884\n",
            "Epoch 23/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.6690 - mae: 11.6690\n",
            "Epoch 24/230\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.6491 - mae: 11.6491\n",
            "Epoch 25/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.6287 - mae: 11.6287\n",
            "Epoch 26/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.6076 - mae: 11.6076\n",
            "Epoch 27/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.5860 - mae: 11.5860\n",
            "Epoch 28/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.5637 - mae: 11.5637\n",
            "Epoch 29/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.5408 - mae: 11.5408\n",
            "Epoch 30/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.5172 - mae: 11.5172\n",
            "Epoch 31/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.4929 - mae: 11.4929\n",
            "Epoch 32/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.4678 - mae: 11.4678\n",
            "Epoch 33/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.4420 - mae: 11.4420\n",
            "Epoch 34/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.4154 - mae: 11.4154\n",
            "Epoch 35/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.3880 - mae: 11.3880\n",
            "Epoch 36/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.3598 - mae: 11.3598\n",
            "Epoch 37/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.3307 - mae: 11.3307\n",
            "Epoch 38/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.3006 - mae: 11.3006\n",
            "Epoch 39/230\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 11.2696 - mae: 11.2696\n",
            "Epoch 40/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.2377 - mae: 11.2377\n",
            "Epoch 41/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.2047 - mae: 11.2047\n",
            "Epoch 42/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.1707 - mae: 11.1707\n",
            "Epoch 43/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.1356 - mae: 11.1356\n",
            "Epoch 44/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.0994 - mae: 11.0994\n",
            "Epoch 45/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.0621 - mae: 11.0621\n",
            "Epoch 46/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.0235 - mae: 11.0235\n",
            "Epoch 47/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.9837 - mae: 10.9837\n",
            "Epoch 48/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.9426 - mae: 10.9426\n",
            "Epoch 49/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.9002 - mae: 10.9002\n",
            "Epoch 50/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.8565 - mae: 10.8565\n",
            "Epoch 51/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.8113 - mae: 10.8113\n",
            "Epoch 52/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.7647 - mae: 10.7647\n",
            "Epoch 53/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.7166 - mae: 10.7166\n",
            "Epoch 54/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.6669 - mae: 10.6669\n",
            "Epoch 55/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.6157 - mae: 10.6157\n",
            "Epoch 56/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.5628 - mae: 10.5628\n",
            "Epoch 57/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.5082 - mae: 10.5082\n",
            "Epoch 58/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.4518 - mae: 10.4518\n",
            "Epoch 59/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.3936 - mae: 10.3936\n",
            "Epoch 60/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.3336 - mae: 10.3336\n",
            "Epoch 61/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.2716 - mae: 10.2716\n",
            "Epoch 62/230\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.2077 - mae: 10.2077\n",
            "Epoch 63/230\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.1417 - mae: 10.1417\n",
            "Epoch 64/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.0737 - mae: 10.0737\n",
            "Epoch 65/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.0034 - mae: 10.0034\n",
            "Epoch 66/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.9310 - mae: 9.9310\n",
            "Epoch 67/230\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.8562 - mae: 9.8562\n",
            "Epoch 68/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.7791 - mae: 9.7791\n",
            "Epoch 69/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.6995 - mae: 9.6995\n",
            "Epoch 70/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.6175 - mae: 9.6175\n",
            "Epoch 71/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.5329 - mae: 9.5329\n",
            "Epoch 72/230\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.4456 - mae: 9.4456\n",
            "Epoch 73/230\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 9.3556 - mae: 9.3556\n",
            "Epoch 74/230\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.2628 - mae: 9.2628\n",
            "Epoch 75/230\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.1672 - mae: 9.1672\n",
            "Epoch 76/230\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.0685 - mae: 9.0685\n",
            "Epoch 77/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.9669 - mae: 8.9669\n",
            "Epoch 78/230\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 8.8621 - mae: 8.8621\n",
            "Epoch 79/230\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.7540 - mae: 8.7540\n",
            "Epoch 80/230\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.6427 - mae: 8.6427\n",
            "Epoch 81/230\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 8.5280 - mae: 8.5280\n",
            "Epoch 82/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.4098 - mae: 8.4098\n",
            "Epoch 83/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.2881 - mae: 8.2881\n",
            "Epoch 84/230\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.1626 - mae: 8.1626\n",
            "Epoch 85/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.0334 - mae: 8.0334\n",
            "Epoch 86/230\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 7.9003 - mae: 7.9003\n",
            "Epoch 87/230\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.7633 - mae: 7.7633\n",
            "Epoch 88/230\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.6221 - mae: 7.6221\n",
            "Epoch 89/230\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.4768 - mae: 7.4768\n",
            "Epoch 90/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.3272 - mae: 7.3272\n",
            "Epoch 91/230\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1732 - mae: 7.1732\n",
            "Epoch 92/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0146 - mae: 7.0146\n",
            "Epoch 93/230\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.8514 - mae: 6.8514\n",
            "Epoch 94/230\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.6835 - mae: 6.6835\n",
            "Epoch 95/230\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.5107 - mae: 6.5107\n",
            "Epoch 96/230\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.3329 - mae: 6.3329\n",
            "Epoch 97/230\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.1499 - mae: 6.1499\n",
            "Epoch 98/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.9618 - mae: 5.9618\n",
            "Epoch 99/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.7682 - mae: 5.7682\n",
            "Epoch 100/230\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.5691 - mae: 5.5691\n",
            "Epoch 101/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.3644 - mae: 5.3644\n",
            "Epoch 102/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.1539 - mae: 5.1539\n",
            "Epoch 103/230\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.9375 - mae: 4.9375\n",
            "Epoch 104/230\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.7150 - mae: 4.7150\n",
            "Epoch 105/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.4863 - mae: 4.4863\n",
            "Epoch 106/230\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.2513 - mae: 4.2513\n",
            "Epoch 107/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0097 - mae: 4.0097\n",
            "Epoch 108/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8680 - mae: 3.8680\n",
            "Epoch 109/230\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8285 - mae: 3.8285\n",
            "Epoch 110/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7891 - mae: 3.7891\n",
            "Epoch 111/230\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8490 - mae: 3.8490\n",
            "Epoch 112/230\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.8770 - mae: 3.8770\n",
            "Epoch 113/230\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8776 - mae: 3.8776\n",
            "Epoch 114/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8546 - mae: 3.8546\n",
            "Epoch 115/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8117 - mae: 3.8117\n",
            "Epoch 116/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7521 - mae: 3.7521\n",
            "Epoch 117/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6785 - mae: 3.6785\n",
            "Epoch 118/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5935 - mae: 3.5935\n",
            "Epoch 119/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4993 - mae: 3.4993\n",
            "Epoch 120/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3979 - mae: 3.3979\n",
            "Epoch 121/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.2908 - mae: 3.2908\n",
            "Epoch 122/230\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.1796 - mae: 3.1796\n",
            "Epoch 123/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1237 - mae: 3.1237\n",
            "Epoch 124/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0754 - mae: 3.0754\n",
            "Epoch 125/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0264 - mae: 3.0264\n",
            "Epoch 126/230\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9766 - mae: 2.9766\n",
            "Epoch 127/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.9260 - mae: 2.9260\n",
            "Epoch 128/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8774 - mae: 2.8774\n",
            "Epoch 129/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8426 - mae: 2.8426\n",
            "Epoch 130/230\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7813 - mae: 2.7813\n",
            "Epoch 131/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7066 - mae: 2.7066\n",
            "Epoch 132/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6477 - mae: 2.6477\n",
            "Epoch 133/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5881 - mae: 2.5881\n",
            "Epoch 134/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5277 - mae: 2.5277\n",
            "Epoch 135/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4665 - mae: 2.4665\n",
            "Epoch 136/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4044 - mae: 2.4044\n",
            "Epoch 137/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3416 - mae: 2.3416\n",
            "Epoch 138/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2779 - mae: 2.2779\n",
            "Epoch 139/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2133 - mae: 2.2133\n",
            "Epoch 140/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1477 - mae: 2.1477\n",
            "Epoch 141/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0813 - mae: 2.0813\n",
            "Epoch 142/230\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.0326 - mae: 2.0326\n",
            "Epoch 143/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9792 - mae: 1.9792\n",
            "Epoch 144/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9165 - mae: 1.9165\n",
            "Epoch 145/230\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8460 - mae: 1.8460\n",
            "Epoch 146/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7688 - mae: 1.7688\n",
            "Epoch 147/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7045 - mae: 1.7045\n",
            "Epoch 148/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6444 - mae: 1.6444\n",
            "Epoch 149/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5825 - mae: 1.5825\n",
            "Epoch 150/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5188 - mae: 1.5188\n",
            "Epoch 151/230\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4534 - mae: 1.4534\n",
            "Epoch 152/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3862 - mae: 1.3862\n",
            "Epoch 153/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3173 - mae: 1.3173\n",
            "Epoch 154/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2467 - mae: 1.2467\n",
            "Epoch 155/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1744 - mae: 1.1744\n",
            "Epoch 156/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1005 - mae: 1.1005\n",
            "Epoch 157/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0248 - mae: 1.0248\n",
            "Epoch 158/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9474 - mae: 0.9474\n",
            "Epoch 159/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8831 - mae: 0.8831\n",
            "Epoch 160/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8152 - mae: 0.8152\n",
            "Epoch 161/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7407 - mae: 0.7407\n",
            "Epoch 162/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6605 - mae: 0.6605\n",
            "Epoch 163/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5756 - mae: 0.5756\n",
            "Epoch 164/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5066 - mae: 0.5066\n",
            "Epoch 165/230\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.4352 - mae: 0.4352\n",
            "Epoch 166/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3709 - mae: 0.3709\n",
            "Epoch 167/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2836 - mae: 0.2836\n",
            "Epoch 168/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1918 - mae: 0.1918\n",
            "Epoch 169/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1273 - mae: 0.1273\n",
            "Epoch 170/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0656 - mae: 0.0656\n",
            "Epoch 171/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0405 - mae: 0.0405\n",
            "Epoch 172/230\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1207 - mae: 0.1207\n",
            "Epoch 173/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.1809 - mae: 0.1809\n",
            "Epoch 174/230\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2092 - mae: 0.2092\n",
            "Epoch 175/230\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2116 - mae: 0.2116\n",
            "Epoch 176/230\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2133 - mae: 0.2133\n",
            "Epoch 177/230\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2146 - mae: 0.2146\n",
            "Epoch 178/230\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.2235 - mae: 0.2235\n",
            "Epoch 179/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2034 - mae: 0.2034\n",
            "Epoch 180/230\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1726 - mae: 0.1726\n",
            "Epoch 181/230\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.1559 - mae: 0.1559\n",
            "Epoch 182/230\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.1336 - mae: 0.1336\n",
            "Epoch 183/230\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0964 - mae: 0.0964\n",
            "Epoch 184/230\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0465 - mae: 0.0465\n",
            "Epoch 185/230\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0254 - mae: 0.0254\n",
            "Epoch 186/230\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0399 - mae: 0.0399\n",
            "Epoch 187/230\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0733 - mae: 0.0733\n",
            "Epoch 188/230\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0900 - mae: 0.0900\n",
            "Epoch 189/230\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1064 - mae: 0.1064\n",
            "Epoch 190/230\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1114 - mae: 0.1114\n",
            "Epoch 191/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1054 - mae: 0.1054\n",
            "Epoch 192/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0896 - mae: 0.0896\n",
            "Epoch 193/230\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0737 - mae: 0.0737\n",
            "Epoch 194/230\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0470 - mae: 0.0470\n",
            "Epoch 195/230\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0286 - mae: 0.0286\n",
            "Epoch 196/230\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0117 - mae: 0.0117\n",
            "Epoch 197/230\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0606 - mae: 0.0606\n",
            "Epoch 198/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0768 - mae: 0.0768\n",
            "Epoch 199/230\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0639 - mae: 0.0639\n",
            "Epoch 200/230\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0619 - mae: 0.0619\n",
            "Epoch 201/230\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0647 - mae: 0.0647\n",
            "Epoch 202/230\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0351 - mae: 0.0351\n",
            "Epoch 203/230\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0352 - mae: 0.0352\n",
            "Epoch 204/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0240 - mae: 0.0240\n",
            "Epoch 205/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0294 - mae: 0.0294\n",
            "Epoch 206/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0464 - mae: 0.0464\n",
            "Epoch 207/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0354 - mae: 0.0354\n",
            "Epoch 208/230\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0513 - mae: 0.0513\n",
            "Epoch 209/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0483 - mae: 0.0483\n",
            "Epoch 210/230\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0131 - mae: 0.0131\n",
            "Epoch 211/230\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0511 - mae: 0.0511\n",
            "Epoch 212/230\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0759 - mae: 0.0759\n",
            "Epoch 213/230\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0657 - mae: 0.0657\n",
            "Epoch 214/230\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0249 - mae: 0.0249\n",
            "Epoch 215/230\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0480 - mae: 0.0480\n",
            "Epoch 216/230\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0572 - mae: 0.0572\n",
            "Epoch 217/230\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0379 - mae: 0.0379\n",
            "Epoch 218/230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0266 - mae: 0.0266\n",
            "Epoch 219/230\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0407 - mae: 0.0407\n",
            "Epoch 220/230\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0240 - mae: 0.0240\n",
            "Epoch 221/230\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.0306 - mae: 0.0306\n",
            "Epoch 222/230\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0396 - mae: 0.0396\n",
            "Epoch 223/230\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0212 - mae: 0.0212\n",
            "Epoch 224/230\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0478 - mae: 0.0478\n",
            "Epoch 225/230\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0605 - mae: 0.0605\n",
            "Epoch 226/230\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0415 - mae: 0.0415\n",
            "Epoch 227/230\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0054 - mae: 0.0054\n",
            "Epoch 228/230\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0176 - mae: 0.0176\n",
            "Epoch 229/230\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.0135 - mae: 0.0135\n",
            "Epoch 230/230\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0038 - mae: 0.0038\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f15ebfe6b10>"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict([23.0]) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SkCcmYJiIAu",
        "outputId": "68d7610c-c840-472e-aa59-d0a5e645b699"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[32.97749]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Well after some adjustments I got this which is really near to actual result\n",
        "\n",
        "'''\n",
        "    Highlight: Learning Rate is really mportnat\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "kQwDonVOm91I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}